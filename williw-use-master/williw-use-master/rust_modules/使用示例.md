# Rust 模块使用示例

本文档展示如何将 Rust 模块作为依赖集成到算法层。

## 作为依赖使用

### 方法1: 本地路径依赖

在您的项目 `Cargo.toml` 中添加：

```toml
[dependencies]
model-downloader = { path = "../rust_modules/model-downloader" }
metadata-generator = { path = "../rust_modules/metadata-generator" }
metadata-uploader = { path = "../rust_modules/metadata-uploader" }
model-splitter = { path = "../rust_modules/model-splitter" }

tokio = { version = "1", features = ["full"] }
anyhow = "1.0"
```

### 方法2: Git 依赖

```toml
[dependencies]
model-downloader = { git = "https://github.com/williw/model-downloader" }
metadata-generator = { git = "https://github.com/williw/metadata-generator" }
metadata-uploader = { git = "https://github.com/williw/metadata-uploader" }
model-splitter = { git = "https://github.com/williw/model-splitter" }
```

### 方法3: 发布到 crates.io（未来）

```toml
[dependencies]
model-downloader = "0.1.0"
metadata-generator = "0.1.0"
metadata-uploader = "0.1.0"
model-splitter = "0.1.0"
```

## 完整使用示例

### 示例1: 完整工作流程

```rust
use model_downloader::{ModelDownloader, DownloadConfig};
use metadata_generator::{MetadataGenerator, MetadataConfig};
use metadata_uploader::{MetadataUploader, UploadConfig};
use model_splitter::{ModelSplitter, SplitConfig, SplitPlan};
use std::collections::HashMap;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let model_name = "meta-llama/Llama-3.2-1B-Instruct";
    let hf_token = std::env::var("HF_TOKEN")?;
    let metadata_repo = "your-username/model-metadata";
    let node_id = "node_001";
    
    // 步骤1: 下载模型
    println!("步骤1: 下载模型...");
    let downloader = ModelDownloader::new(Some(hf_token.clone()));
    let download_config = DownloadConfig {
        model_name: model_name.to_string(),
        cache_dir: Some("./models_cache".to_string()),
        hf_token: Some(hf_token.clone()),
    };
    let download_result = downloader.download_model(download_config).await?;
    println!("✓ 模型下载完成: {}", download_result.model_path);
    
    // 步骤2: 生成元数据
    println!("步骤2: 生成元数据...");
    let generator = MetadataGenerator::new();
    let metadata_config = MetadataConfig {
        model_name: model_name.to_string(),
        model_path: download_result.model_path.clone(),
        batch_size: 1,
        sequence_length: 512,
        node_id: Some(node_id.to_string()),
    };
    let metadata = generator.generate_metadata(metadata_config).await?;
    let metadata_file = format!("./{}_metadata.json", model_name.replace("/", "_"));
    generator.save_metadata(&metadata, &metadata_file).await?;
    println!("✓ 元数据生成完成: {}", metadata_file);
    
    // 步骤3: 上传元数据
    println!("步骤3: 上传元数据...");
    let uploader = MetadataUploader::new();
    let upload_config = UploadConfig {
        metadata_file: metadata_file.clone(),
        repo_id: metadata_repo.to_string(),
        hf_token: hf_token.clone(),
        commit_message: Some(format!("Upload metadata for {}", model_name)),
    };
    let upload_result = uploader.upload_metadata(upload_config).await?;
    println!("✓ 元数据已上传: {}", upload_result.url);
    
    // 步骤4: 从 Worker 获取切分方案（这里模拟）
    println!("步骤4: 获取切分方案...");
    // 实际应该从 Worker API 获取
    let mut split_plan = HashMap::new();
    split_plan.insert(
        node_id.to_string(),
        SplitPlan {
            node_id: node_id.to_string(),
            layer_names: metadata.layers.iter()
                .take(10)
                .map(|l| l.name.clone())
                .collect(),
            total_compute: metadata.total_compute / 3.0,
            compute_utilization: 0.5,
        },
    );
    
    // 步骤5: 切分模型
    println!("步骤5: 切分模型...");
    let splitter = ModelSplitter::new();
    let split_config = SplitConfig {
        model_name: model_name.to_string(),
        model_path: download_result.model_path,
        split_plan,
        output_dir: Some("./model_shards".to_string()),
    };
    let split_result = splitter.split_model(split_config, node_id).await?;
    println!("✓ 模型切分完成: {}", split_result.shard_path);
    
    Ok(())
}
```

### 示例2: 在算法层中使用

```rust
// algorithms/model_processor.rs
use model_downloader::ModelDownloader;
use metadata_generator::MetadataGenerator;
use metadata_uploader::MetadataUploader;
use model_splitter::ModelSplitter;

pub struct ModelProcessor {
    downloader: ModelDownloader,
    generator: MetadataGenerator,
    uploader: MetadataUploader,
    splitter: ModelSplitter,
}

impl ModelProcessor {
    pub fn new(hf_token: Option<String>) -> Self {
        Self {
            downloader: ModelDownloader::new(hf_token.clone()),
            generator: MetadataGenerator::new(),
            uploader: MetadataUploader::new(),
            splitter: ModelSplitter::new(),
        }
    }
    
    pub async fn process_model(
        &self,
        model_name: &str,
        node_id: &str,
    ) -> anyhow::Result<()> {
        // 使用各个模块处理模型
        // ...
        Ok(())
    }
}
```

## 编译和测试

### 编译所有模块

```bash
cd rust_modules
cargo build --workspace
```

### 编译单个模块

```bash
cd rust_modules/model-downloader
cargo build
```

### 运行测试

```bash
cd rust_modules
cargo test --workspace
```

### 运行单个模块的测试

```bash
cd rust_modules/model-downloader
cargo test
```

## 集成到 Python 项目

如果您需要在 Python 项目中使用这些 Rust 模块，可以使用 `pyo3` 创建 Python 绑定：

```rust
// py_bindings/src/lib.rs
use pyo3::prelude::*;
use model_downloader::{ModelDownloader, DownloadConfig};

#[pyfunction]
fn download_model(model_name: String, cache_dir: Option<String>) -> PyResult<String> {
    // 调用 Rust 模块
    // ...
}

#[pymodule]
fn williw_rust_modules(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(download_model, m)?)?;
    Ok(())
}
```

然后在 Python 中使用：

```python
import williw_rust_modules

result = williw_rust_modules.download_model(
    "meta-llama/Llama-3.2-1B-Instruct",
    "./cache"
)
```

## 注意事项

1. **Python 依赖**：`metadata-generator` 和 `model-splitter` 需要 Python 环境
2. **Hugging Face Token**：某些操作需要有效的 HF Token
3. **异步运行时**：所有模块都使用 `tokio`，需要异步运行时
4. **错误处理**：使用 `anyhow::Result` 进行错误处理
