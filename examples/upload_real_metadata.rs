/**
 * ä½¿ç”¨çœŸå®ä¸‹è½½çš„æ¨¡å‹æ•°æ®åˆ›å»ºå…ƒæ•°æ®å¹¶ä¸Šä¼ åˆ° HF
 * ç›®æ ‡ä»“åº“: https://huggingface.co/logos42/williw
 */
use metadata_uploader::{MetadataUploader, UploadConfig};
use serde_json;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ å¼€å§‹ä½¿ç”¨çœŸå®æ¨¡å‹æ•°æ®åˆ›å»ºå¹¶ä¸Šä¼ å…ƒæ•°æ®");
    
    // ==================== åˆ›å»ºçœŸå®æ¨¡å‹å…ƒæ•°æ® ====================
    println!("\nğŸ“Š åŸºäºå·²ä¸‹è½½çš„æ¨¡å‹åˆ›å»ºå…ƒæ•°æ®...");
    
    // åŸºäºå®é™… config.json çš„æ¨¡å‹ä¿¡æ¯
    let model_metadata = serde_json::json!({
        "model_info": {
            "model_name": "LiquidAI/LFM2.5-1.2B-Thinking",
            "model_type": "lfm2",
            "architecture": "Lfm2ForCausalLM",
            "hidden_size": 2048,
            "intermediate_size": 12288,
            "num_attention_heads": 32,
            "num_key_value_heads": 8,
            "num_hidden_layers": 16,
            "vocab_size": 65536,
            "max_position_embeddings": 128000,
            "dtype": "bfloat16",
            "layer_types": [
                "conv", "conv", "full_attention", "conv", "conv", "full_attention",
                "conv", "conv", "full_attention", "conv", "full_attention",
                "conv", "full_attention", "conv", "full_attention", "conv"
            ],
            "file_size_gb": 2.34,
            "estimated_params": 1240000000,
            "download_path": "./test_models/models--LiquidAI--LFM2.5-1.2B-Thinking/snapshots/3c58ec1db4a336594e9ac4ad3fff10fc8aa22d70"
        },
        "split_plan": {
            "strategy": "layer_based_balanced",
            "num_nodes": 2,
            "total_params": 1240000000,
            "created_at": "2026-01-25T08:50:00Z",
            "splits": [
                {
                    "node_id": "node_001",
                    "layer_range": "0-7",
                    "layer_types": ["conv", "conv", "full_attention", "conv", "conv", "full_attention", "conv", "conv"],
                    "num_layers": 8,
                    "estimated_params": 620000000,
                    "estimated_size_gb": 1.17,
                    "compute_intensity": "medium",
                    "memory_requirement_mb": 1200,
                    "description": "å‰8å±‚ï¼šåŒ…å«4ä¸ªå·ç§¯å±‚å’Œ2ä¸ªæ³¨æ„åŠ›å±‚"
                },
                {
                    "node_id": "node_002", 
                    "layer_range": "8-15",
                    "layer_types": ["full_attention", "conv", "full_attention", "conv", "full_attention", "conv", "full_attention", "conv"],
                    "num_layers": 8,
                    "estimated_params": 620000000,
                    "estimated_size_gb": 1.17,
                    "compute_intensity": "high",
                    "memory_requirement_mb": 1200,
                    "description": "å8å±‚ï¼šåŒ…å«4ä¸ªæ³¨æ„åŠ›å±‚å’Œ4ä¸ªå·ç§¯å±‚"
                }
            ]
        },
        "distribution_config": {
            "load_balancing": "equal_split",
            "fault_tolerance": true,
            "compression": "none",
            "encryption": "optional",
            "sync_protocol": "p2p",
            "heartbeat_interval_ms": 5000
        },
        "training_config": {
            "batch_size_per_node": 32,
            "learning_rate": 1e-4,
            "optimizer": "adamw",
            "scheduler": "cosine",
            "max_epochs": 100,
            "gradient_accumulation_steps": 4,
            "mixed_precision": true
        },
        "metadata_info": {
            "version": "1.0.0",
            "created_by": "williw_model_splitter",
            "created_at": "2026-01-25T08:50:00Z",
            "purpose": "decentralized_training",
            "framework": "rust+python",
            "notes": "åŸºäºå®é™…ä¸‹è½½çš„LiquidAI LFM2.5-1.2B-Thinkingæ¨¡å‹åˆ›å»ºçš„æ‹†åˆ†å…ƒæ•°æ®"
        }
    });
    
    // ä¿å­˜å…ƒæ•°æ®åˆ°æ–‡ä»¶
    let metadata_file = "./test_models/lfm2_1.2b_split_metadata.json";
    std::fs::create_dir_all("./test_models")?;
    std::fs::write(metadata_file, serde_json::to_string_pretty(&model_metadata)?)?;
    
    println!("âœ… çœŸå®æ¨¡å‹å…ƒæ•°æ®å·²åˆ›å»º: {}", metadata_file);
    
    // æ˜¾ç¤ºå…ƒæ•°æ®æ‘˜è¦
    println!("\nğŸ“‹ å…ƒæ•°æ®æ‘˜è¦:");
    println!("   - æ¨¡å‹: {}", model_metadata["model_info"]["model_name"]);
    println!("   - å±‚æ•°: {}", model_metadata["model_info"]["num_hidden_layers"]);
    println!("   - å‚æ•°é‡: {:?}", model_metadata["model_info"]["estimated_params"]);
    println!("   - æ‹†åˆ†èŠ‚ç‚¹æ•°: {}", model_metadata["split_plan"]["num_nodes"]);
    
    for (i, split) in model_metadata["split_plan"]["splits"].as_array().unwrap().iter().enumerate() {
        println!("   - èŠ‚ç‚¹ {}: {} å±‚, {:.2} GB", 
                 i+1, 
                 split["num_layers"], 
                 split["estimated_size_gb"]);
    }
    
    // ==================== ä¸Šä¼ åˆ° Hugging Face ====================
    println!("\nğŸ“¤ å‡†å¤‡ä¸Šä¼ åˆ° Hugging Face ä»“åº“: logos42/williw");
    
    // æ£€æŸ¥æ˜¯å¦æœ‰ HF token
    let hf_token = std::env::var("HF_TOKEN").ok();
    
    if hf_token.is_none() {
        println!("âš ï¸  æœªè®¾ç½® HF_TOKEN ç¯å¢ƒå˜é‡");
        println!("ğŸ’¡ è¯·è®¾ç½® HF token åé‡æ–°è¿è¡Œ:");
        println!("   set HF_TOKEN=your_huggingface_token");
        println!("   cargo run --example upload_real_metadata");
        return Ok(());
    }
    
    println!("ğŸ”‘ æ‰¾åˆ° HF tokenï¼Œå¼€å§‹ä¸Šä¼ ...");
    
    let uploader = MetadataUploader::new();
    let upload_config = UploadConfig {
        metadata_file: metadata_file.to_string(),
        repo_id: "logos42/williw".to_string(),
        hf_token: hf_token.unwrap(),
        commit_message: Some("Add LFM2.5-1.2B-Thinking model split metadata for decentralized training".to_string()),
    };
    
    println!("ğŸš€ å¼€å§‹ä¸Šä¼ åˆ° https://huggingface.co/logos42/williw...");
    
    match uploader.upload_metadata(upload_config).await {
        Ok(result) => {
            println!("ğŸ‰ ä¸Šä¼ æˆåŠŸ!");
            println!("ğŸ“Š ä¸Šä¼ ç»“æœ:");
            println!("   - ä»“åº“: {}", result.repo);
            println!("   - æ–‡ä»¶: {}", result.filename);
            println!("   - è®¿é—®URL: {}", result.url);
            println!("   - æäº¤URL: {}", result.commit_url);
            
            println!("\nâœ… å…ƒæ•°æ®å·²æˆåŠŸä¸Šä¼ åˆ° Hugging Face!");
            println!("ğŸ’¡ ä½ ç°åœ¨å¯ä»¥:");
            println!("   1. è®¿é—® https://huggingface.co/logos42/williw æŸ¥çœ‹å…ƒæ•°æ®");
            println!("   2. ä½¿ç”¨è¿™ä¸ªå…ƒæ•°æ®è¿›è¡Œæ¨¡å‹æ‹†åˆ†");
            println!("   3. å¼€å§‹åˆ†å¸ƒå¼è®­ç»ƒ");
        }
        Err(e) => {
            println!("âŒ ä¸Šä¼ å¤±è´¥: {}", e);
            println!("ğŸ’¡ å¯èƒ½åŸå› :");
            println!("   - HF token æ— æ•ˆæˆ–è¿‡æœŸ");
            println!("   - å¯¹ logos42/williw ä»“åº“æ²¡æœ‰å†™æƒé™");
            println!("   - ç½‘ç»œè¿æ¥é—®é¢˜");
            println!("   - ä»“åº“ä¸å­˜åœ¨");
            
            println!("\nğŸ”§ è§£å†³æ–¹æ¡ˆ:");
            println!("   1. æ£€æŸ¥ HF token: huggingface-cli whoami");
            println!("   2. ç¡®ä¿ä»“åº“å­˜åœ¨: https://huggingface.co/logos42/williw");
            println!("   3. æ£€æŸ¥æƒé™è®¾ç½®");
        }
    }
    
    Ok(())
}
