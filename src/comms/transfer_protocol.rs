/**
 * æ–‡ä»¶ä¼ è¾“åè®®å’Œå®Œæ•´æ€§æ ¡éªŒæ¨¡å—
 * æä¾›å®‰å…¨çš„æ–‡ä»¶ä¼ è¾“å’ŒéªŒè¯åŠŸèƒ½
 */

use anyhow::{anyhow, Result};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use tokio::fs;
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tracing::{info, warn, error, debug};

/// æ–‡ä»¶å®Œæ•´æ€§ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileIntegrity {
    pub file_path: String,
    pub file_size: u64,
    pub sha256_hash: String,
    pub chunk_hashes: HashMap<u32, String>,
    pub created_at: chrono::DateTime<chrono::Utc>,
    pub version: String,
}

impl FileIntegrity {
    pub fn new(file_path: String, file_size: u64, sha256_hash: String) -> Self {
        Self {
            file_path,
            file_size,
            sha256_hash,
            chunk_hashes: HashMap::new(),
            created_at: chrono::Utc::now(),
            version: "1.0".to_string(),
        }
    }

    /// æ·»åŠ å—å“ˆå¸Œ
    pub fn add_chunk_hash(&mut self, chunk_index: u32, hash: String) {
        self.chunk_hashes.insert(chunk_index, hash);
    }

    /// éªŒè¯å—å“ˆå¸Œ
    pub fn verify_chunk_hash(&self, chunk_index: u32, hash: &str) -> bool {
        match self.chunk_hashes.get(&chunk_index) {
            Some(stored_hash) => stored_hash == hash,
            None => false,
        }
    }

    /// è·å–ç¼ºå¤±çš„å—
    pub fn get_missing_chunks(&self, total_chunks: u32) -> Vec<u32> {
        let mut missing = Vec::new();
        for i in 0..total_chunks {
            if !self.chunk_hashes.contains_key(&i) {
                missing.push(i);
            }
        }
        missing
    }

    /// åºåˆ—åŒ–ä¸º JSON
    pub fn to_json(&self) -> Result<String> {
        Ok(serde_json::to_string_pretty(self)?)
    }

    /// ä» JSON ååºåˆ—åŒ–
    pub fn from_json(json: &str) -> Result<Self> {
        Ok(serde_json::from_str(json)?)
    }

    /// ä¿å­˜åˆ°æ–‡ä»¶
    pub async fn save_to_file(&self, file_path: &Path) -> Result<()> {
        let json = self.to_json()?;
        fs::write(file_path, json).await?;
        Ok(())
    }

    /// ä»æ–‡ä»¶åŠ è½½
    pub async fn load_from_file(file_path: &Path) -> Result<Self> {
        let json = fs::read_to_string(file_path).await?;
        Ok(Self::from_json(&json)?)
    }
}

/// æ–‡ä»¶ä¼ è¾“åè®®é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransferProtocolConfig {
    pub max_chunk_size: usize,
    pub max_retries: u32,
    pub timeout_seconds: u64,
    pub enable_compression: bool,
    pub enable_encryption: bool,
    pub checksum_algorithm: ChecksumAlgorithm,
    pub resume_support: bool,
}

/// æ ¡éªŒå’Œç®—æ³•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ChecksumAlgorithm {
    SHA256,
    SHA512,
    MD5,
    Blake3,
}

impl Default for TransferProtocolConfig {
    fn default() -> Self {
        Self {
            max_chunk_size: 1024 * 1024, // 1MB
            max_retries: 3,
            timeout_seconds: 30,
            enable_compression: true,
            enable_encryption: true,
            checksum_algorithm: ChecksumAlgorithm::SHA256,
            resume_support: true,
        }
    }
}

/// æ–‡ä»¶ä¼ è¾“åè®®å®ç°
pub struct FileTransferProtocol {
    config: TransferProtocolConfig,
}

impl FileTransferProtocol {
    pub fn new(config: TransferProtocolConfig) -> Self {
        Self { config }
    }

    /// è®¡ç®—æ–‡ä»¶å®Œæ•´æ€§ä¿¡æ¯
    pub async fn calculate_file_integrity(&self, file_path: &Path) -> Result<FileIntegrity> {
        info!("ğŸ” è®¡ç®—æ–‡ä»¶å®Œæ•´æ€§: {}", file_path.display());

        let metadata = fs::metadata(file_path).await?;
        let file_size = metadata.len();
        let file_path_str = file_path.to_string_lossy().to_string();

        // è®¡ç®—æ•´ä¸ªæ–‡ä»¶çš„å“ˆå¸Œ
        let sha256_hash = self.calculate_file_hash(file_path).await;

        let mut integrity = FileIntegrity::new(file_path_str, file_size, sha256_hash);

        // è®¡ç®—æ¯ä¸ªå—çš„å“ˆå¸Œ
        let mut file = fs::File::open(file_path).await?;
        let mut buffer = vec![0u8; self.config.max_chunk_size];
        let mut chunk_index = 0u32;

        loop {
            let bytes_read = file.read(&mut buffer).await?;
            if bytes_read == 0 {
                break;
            }

            let chunk_data = &buffer[..bytes_read];
            let chunk_hash = self.calculate_chunk_hash(chunk_data);
            integrity.add_chunk_hash(chunk_index, chunk_hash);

            chunk_index += 1;
        }

        info!("âœ… æ–‡ä»¶å®Œæ•´æ€§è®¡ç®—å®Œæˆ: {} ä¸ªå—", chunk_index);
        Ok(integrity)
    }

    /// éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    pub async fn verify_file_integrity(&self, file_path: &Path, integrity: &FileIntegrity) -> Result<bool> {
        info!("ğŸ” éªŒè¯æ–‡ä»¶å®Œæ•´æ€§: {}", file_path.display());

        // æ£€æŸ¥æ–‡ä»¶å¤§å°
        let metadata = fs::metadata(file_path).await?;
        if metadata.len() != integrity.file_size {
            error!("æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {}, å®é™… {}", integrity.file_size, metadata.len());
            return Ok(false);
        }

        // æ£€æŸ¥æ–‡ä»¶å“ˆå¸Œ
        let actual_hash = self.calculate_file_hash(file_path).await;
        if actual_hash != integrity.sha256_hash {
            error!("æ–‡ä»¶å“ˆå¸Œä¸åŒ¹é…: æœŸæœ› {}, å®é™… {}", integrity.sha256_hash, actual_hash);
            return Ok(false);
        }

        // éªŒè¯å—å“ˆå¸Œ
        let mut file = fs::File::open(file_path).await?;
        let mut buffer = vec![0u8; self.config.max_chunk_size];
        let mut chunk_index = 0u32;

        loop {
            let bytes_read = file.read(&mut buffer).await?;
            if bytes_read == 0 {
                break;
            }

            let chunk_data = &buffer[..bytes_read];
            let actual_chunk_hash = self.calculate_chunk_hash(chunk_data);

            if !integrity.verify_chunk_hash(chunk_index, &actual_chunk_hash) {
                error!("å— {} å“ˆå¸Œä¸åŒ¹é…", chunk_index);
                return Ok(false);
            }

            chunk_index += 1;
        }

        info!("âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡");
        Ok(true)
    }

    /// éªŒè¯å•ä¸ªå—
    pub fn verify_chunk(&self, chunk_data: &[u8], expected_hash: &str) -> bool {
        let actual_hash = self.calculate_chunk_hash(chunk_data);
        actual_hash == expected_hash
    }

    /// è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
    async fn calculate_file_hash(&self, file_path: &Path) -> String {
        match self.config.checksum_algorithm {
            ChecksumAlgorithm::SHA256 => self.calculate_sha256_file(file_path).await,
            ChecksumAlgorithm::SHA512 => self.calculate_sha512_file(file_path).await,
            ChecksumAlgorithm::MD5 => self.calculate_md5_file(file_path).await,
            ChecksumAlgorithm::Blake3 => self.calculate_blake3_file(file_path).await,
        }
    }

    /// è®¡ç®—å—å“ˆå¸Œ
    fn calculate_chunk_hash(&self, data: &[u8]) -> String {
        match self.config.checksum_algorithm {
            ChecksumAlgorithm::SHA256 => self.calculate_sha256(data),
            ChecksumAlgorithm::SHA512 => self.calculate_sha512(data),
            ChecksumAlgorithm::MD5 => self.calculate_md5(data),
            ChecksumAlgorithm::Blake3 => self.calculate_blake3(data),
        }
    }

    /// SHA256 å“ˆå¸Œè®¡ç®—
    async fn calculate_sha256_file(&self, file_path: &Path) -> String {
        use sha3::{Sha3_256, Digest};
        
        let mut file = fs::File::open(file_path).await.unwrap();
        let mut hasher = Sha3_256::new();
        let mut buffer = [0u8; 8192];

        loop {
            match file.read(&mut buffer).await {
                Ok(0) => break,
                Ok(n) => hasher.update(&buffer[..n]),
                Err(_) => break,
            }
        }

        hex::encode(hasher.finalize())
    }

    fn calculate_sha256(&self, data: &[u8]) -> String {
        use sha3::{Sha3_256, Digest};
        let mut hasher = Sha3_256::new();
        hasher.update(data);
        hex::encode(hasher.finalize())
    }

    /// SHA512 å“ˆå¸Œè®¡ç®—
    async fn calculate_sha512_file(&self, file_path: &Path) -> String {
        use sha3::{Sha3_512, Digest};
        
        let mut file = fs::File::open(file_path).await.unwrap();
        let mut hasher = Sha3_512::new();
        let mut buffer = [0u8; 8192];

        loop {
            match file.read(&mut buffer).await {
                Ok(0) => break,
                Ok(n) => hasher.update(&buffer[..n]),
                Err(_) => break,
            }
        }

        hex::encode(hasher.finalize())
    }

    fn calculate_sha512(&self, data: &[u8]) -> String {
        use sha3::{Sha3_512, Digest};
        let mut hasher = Sha3_512::new();
        hasher.update(data);
        hex::encode(hasher.finalize())
    }

    /// MD5 å“ˆå¸Œè®¡ç®—
    async fn calculate_md5_file(&self, _file_path: &Path) -> String {
        // æš‚æ—¶ç¦ç”¨MD5ï¼Œè¿”å›é»˜è®¤å€¼
        "default_md5_hash".to_string()
    }

    fn calculate_md5(&self, _data: &[u8]) -> String {
        // æš‚æ—¶ç¦ç”¨MD5ï¼Œè¿”å›é»˜è®¤å€¼
        "default_md5_hash".to_string()
    }

    /// Blake3 å“ˆå¸Œè®¡ç®—
    async fn calculate_blake3_file(&self, file_path: &Path) -> String {
        use blake3::Hasher;
        
        let mut file = fs::File::open(file_path).await.unwrap();
        let mut hasher = Hasher::new();
        let mut buffer = [0u8; 8192];

        loop {
            match file.read(&mut buffer).await {
                Ok(0) => break,
                Ok(n) => {
                    hasher.update(&buffer[..n]);
                }
                Err(_) => break,
            }
        }

        hex::encode(hasher.finalize().as_bytes())
    }

    fn calculate_blake3(&self, data: &[u8]) -> String {
        use blake3::Hasher;
        let mut hasher = Hasher::new();
        hasher.update(data);
        hex::encode(hasher.finalize().as_bytes())
    }

    /// å‹ç¼©æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    pub fn compress_data(&self, data: &[u8]) -> Result<Vec<u8>> {
        if !self.config.enable_compression {
            return Ok(data.to_vec());
        }

        // ä½¿ç”¨ç®€å•çš„å‹ç¼©ç®—æ³•
        // å®é™…å®ç°ä¸­å¯ä»¥ä½¿ç”¨æ›´é«˜æ•ˆçš„å‹ç¼©åº“
        Ok(data.to_vec()) // æš‚æ—¶ä¸å‹ç¼©
    }

    /// è§£å‹æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    pub fn decompress_data(&self, compressed_data: &[u8]) -> Result<Vec<u8>> {
        if !self.config.enable_compression {
            return Ok(compressed_data.to_vec());
        }

        // å¯¹åº”çš„è§£å‹é€»è¾‘
        Ok(compressed_data.to_vec()) // æš‚æ—¶ä¸è§£å‹
    }

    /// åŠ å¯†æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    pub fn encrypt_data(&self, data: &[u8], _key: &[u8]) -> Result<Vec<u8>> {
        // æš‚æ—¶ç¦ç”¨åŠ å¯†åŠŸèƒ½
        Ok(data.to_vec())
    }

    /// è§£å¯†æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    pub fn decrypt_data(&self, encrypted_data: &[u8], _key: &[u8]) -> Result<Vec<u8>> {
        // æš‚æ—¶ç¦ç”¨è§£å¯†åŠŸèƒ½
        Ok(encrypted_data.to_vec())
    }

    /// è·å–é…ç½®
    pub fn config(&self) -> &TransferProtocolConfig {
        &self.config
    }

    /// æ›´æ–°é…ç½®
    pub fn update_config(&mut self, config: TransferProtocolConfig) {
        self.config = config;
    }
}

/// ä¼ è¾“çŠ¶æ€ç®¡ç†å™¨
pub struct TransferStateManager {
    active_transfers: HashMap<String, TransferState>,
}

#[derive(Debug, Clone)]
pub struct TransferState {
    pub transfer_id: String,
    pub file_path: PathBuf,
    pub total_chunks: u32,
    pub completed_chunks: u32,
    pub failed_chunks: u32,
    pub start_time: chrono::DateTime<chrono::Utc>,
    pub last_activity: chrono::DateTime<chrono::Utc>,
    pub status: TransferStatus,
}

#[derive(Debug, Clone)]
pub enum TransferStatus {
    Pending,
    InProgress,
    Paused,
    Completed,
    Failed(String),
    Cancelled,
}

impl TransferStateManager {
    pub fn new() -> Self {
        Self {
            active_transfers: HashMap::new(),
        }
    }

    pub fn create_transfer(&mut self, transfer_id: String, file_path: PathBuf, total_chunks: u32) {
        let state = TransferState {
            transfer_id: transfer_id.clone(),
            file_path,
            total_chunks,
            completed_chunks: 0,
            failed_chunks: 0,
            start_time: chrono::Utc::now(),
            last_activity: chrono::Utc::now(),
            status: TransferStatus::Pending,
        };
        
        self.active_transfers.insert(transfer_id, state);
    }

    pub fn update_progress(&mut self, transfer_id: &str, completed_chunks: u32) {
        if let Some(state) = self.active_transfers.get_mut(transfer_id) {
            state.completed_chunks = completed_chunks;
            state.last_activity = chrono::Utc::now();
            state.status = TransferStatus::InProgress;
        }
    }

    pub fn mark_completed(&mut self, transfer_id: &str) {
        if let Some(state) = self.active_transfers.get_mut(transfer_id) {
            state.status = TransferStatus::Completed;
            state.last_activity = chrono::Utc::now();
        }
    }

    pub fn mark_failed(&mut self, transfer_id: &str, error: String) {
        if let Some(state) = self.active_transfers.get_mut(transfer_id) {
            state.status = TransferStatus::Failed(error);
            state.last_activity = chrono::Utc::now();
        }
    }

    pub fn get_transfer(&self, transfer_id: &str) -> Option<&TransferState> {
        self.active_transfers.get(transfer_id)
    }

    pub fn remove_transfer(&mut self, transfer_id: &str) -> Option<TransferState> {
        self.active_transfers.remove(transfer_id)
    }

    pub fn cleanup_old_transfers(&mut self, max_age_hours: i64) {
        let cutoff = chrono::Utc::now() - chrono::Duration::hours(max_age_hours);
        
        self.active_transfers.retain(|_, state| {
            state.last_activity > cutoff || matches!(state.status, TransferStatus::InProgress)
        });
    }

    pub fn get_all_transfers(&self) -> Vec<&TransferState> {
        self.active_transfers.values().collect()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;
    use tokio::fs;

    #[tokio::test]
    async fn test_file_integrity() {
        let temp_dir = tempdir().unwrap();
        let file_path = temp_dir.path().join("test.txt");
        
        // åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        fs::write(&file_path, b"Hello, World!").await.unwrap();
        
        let protocol = FileTransferProtocol::new(TransferProtocolConfig::default());
        let integrity = protocol.calculate_file_integrity(&file_path).await.unwrap();
        
        assert_eq!(integrity.file_size, 13);
        assert!(!integrity.sha256_hash.is_empty());
        assert_eq!(integrity.chunk_hashes.len(), 1); // ä¸€ä¸ªå—
        
        // éªŒè¯å®Œæ•´æ€§
        let is_valid = protocol.verify_file_integrity(&file_path, &integrity).await.unwrap();
        assert!(is_valid);
    }

    #[tokio::test]
    async fn test_transfer_state_manager() {
        let mut manager = TransferStateManager::new();
        let transfer_id = "test_transfer".to_string();
        let file_path = PathBuf::from("/tmp/test.txt");
        
        manager.create_transfer(transfer_id.clone(), file_path, 10);
        
        let state = manager.get_transfer(&transfer_id).unwrap();
        assert_eq!(state.total_chunks, 10);
        assert_eq!(state.completed_chunks, 0);
        
        manager.update_progress(&transfer_id, 5);
        let state = manager.get_transfer(&transfer_id).unwrap();
        assert_eq!(state.completed_chunks, 5);
        
        manager.mark_completed(&transfer_id);
        let state = manager.get_transfer(&transfer_id).unwrap();
        assert!(matches!(state.status, TransferStatus::Completed));
    }
}
