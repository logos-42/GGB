use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use crate::state::{DeviceInfo, ModelConfig, TrainingStatus};
use anyhow::Result;

/// Workers后端API客户端
pub struct WorkersApiClient {
    client: reqwest::Client,
    base_url: String,
}

/// 设备信息上传数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceInfoPayload {
    pub device_id: String,
    pub timestamp: String,
    pub device_info: DeviceInfo,
    pub metadata: DeviceMetadata,
}

/// 设备元数据
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceMetadata {
    pub platform: String,
    pub app_version: String,
    pub node_id: Option<String>,
    pub capabilities: HashMap<String, serde_json::Value>,
}

/// 模型选择上传数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSelectionPayload {
    pub device_id: String,
    pub timestamp: String,
    pub model_selection: ModelSelectionData,
    pub training_config: TrainingConfigData,
}

/// 模型选择数据
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSelectionData {
    pub model_id: String,
    pub model_name: String,
    pub selected_at: String,
    pub selection_reason: Option<String>,
}

/// 训练配置数据
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingConfigData {
    pub learning_rate: f64,
    pub batch_size: usize,
    pub epochs: u32,
    pub enable_distributed: bool,
}

/// 训练状态上传数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingStatusPayload {
    pub device_id: String,
    pub timestamp: String,
    pub training_status: TrainingStatus,
    pub node_id: Option<String>,
}

/// 推理请求数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceRequestPayload {
    pub device_id: String,
    pub timestamp: String,
    pub model_id: String,
    pub input_data: serde_json::Value,
}

/// 推理请求响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceRequestResponse {
    pub success: bool,
    pub message: String,
    pub request_id: Option<String>,
    pub selected_nodes: Vec<NodeInfo>,
    pub model_split_plan: ModelSplitPlan,
    pub estimated_total_time: u32, // 毫秒
    pub fallback_nodes: Vec<NodeInfo>, // 备选节点
}

/// 节点信息
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeInfo {
    pub node_id: String,
    pub endpoint: String,
    pub capabilities: NodeCapabilities,
    pub current_load: f32, // 0.0 - 1.0
    pub latency: Option<u32>, // 毫秒
    pub reliability: f32, // 0.0 - 1.0
}

/// 节点能力
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeCapabilities {
    pub max_memory_gb: f64,
    pub gpu_type: Option<String>,
    pub gpu_memory_gb: Option<f64>,
    pub cpu_cores: u32,
    pub network_bandwidth_mbps: u32,
    pub supported_models: Vec<String>,
}

/// 模型切分方案
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSplitPlan {
    pub total_layers: u32,
    pub splits: Vec<ModelSplit>,
    pub communication_overhead: f64, // MB
    pub estimated_inference_time: u32, // 毫秒
}

/// 模型切分信息
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelSplit {
    pub layer_range: (u32, u32), // (start_layer, end_layer)
    pub assigned_node: String,
    pub memory_requirement_mb: u64,
    pub compute_requirement: f32, // GFLOPs
}

/// 节点重新分配请求数据结构
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeReassignmentPayload {
    pub device_id: String,
    pub timestamp: String,
    pub failed_nodes: Vec<String>,
    pub current_splits: Vec<ModelSplit>,
    pub request_id: String,
}

/// 节点重新分配响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeReassignmentResponse {
    pub success: bool,
    pub message: String,
    pub new_splits: Option<Vec<ModelSplit>>,
    pub reassigned_nodes: Vec<NodeInfo>,
}

/// 节点健康状态响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NodeHealthResponse {
    pub success: bool,
    pub message: String,
    pub node_id: String,
    pub is_healthy: bool,
    pub last_seen: Option<String>,
    pub current_load: Option<f32>,
    pub issues: Vec<String>,
}

/// API响应
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApiResponse {
    pub success: bool,
    pub message: String,
    pub data: Option<serde_json::Value>,
}

impl WorkersApiClient {
    /// 创建新的API客户端
    pub fn new(base_url: String) -> Self {
        let client = reqwest::Client::builder()
            .timeout(std::time::Duration::from_secs(30))
            .build()
            .expect("Failed to create HTTP client");
        
        Self {
            client,
            base_url,
        }
    }

    /// 上传设备信息和节点状态到 /api/node-info 端点
    pub async fn upload_node_info_from_device(&self, device_info: DeviceInfo) -> Result<ApiResponse> {
        let payload = DeviceInfoPayload {
            device_id: self.get_device_id(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            device_info,
            metadata: self.get_device_metadata(),
        };

        let response = self.client
            .post(&format!("{}/api/node-info", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let api_response: ApiResponse = response.json().await?;
        Ok(api_response)
    }

    /// 上传桌面选定的模型到 /api/model 端点
    pub async fn upload_selected_model(&self, model_config: ModelConfig, training_config: TrainingConfigData) -> Result<ApiResponse> {
        let payload = ModelSelectionPayload {
            device_id: self.get_device_id(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            model_selection: ModelSelectionData {
                model_id: model_config.id,
                model_name: model_config.name,
                selected_at: chrono::Utc::now().to_rfc3339(),
                selection_reason: Some("User selected from desktop interface".to_string()),
            },
            training_config,
        };

        let response = self.client
            .post(&format!("{}/api/model", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let api_response: ApiResponse = response.json().await?;
        Ok(api_response)
    }

    /// 用户发起推理请求到 /api/request 端点
    pub async fn request_inference(&self, model_id: String, input_data: serde_json::Value) -> Result<InferenceRequestResponse> {
        let payload = InferenceRequestPayload {
            device_id: self.get_device_id(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            model_id,
            input_data,
        };

        let response = self.client
            .post(&format!("{}/api/request", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let inference_response: InferenceRequestResponse = response.json().await?;
        Ok(inference_response)
    }

    /// 上传训练数据样本到 /api/training-data 端点
    pub async fn upload_training_data(&self, training_status: TrainingStatus, node_id: Option<String>) -> Result<ApiResponse> {
        let payload = TrainingStatusPayload {
            device_id: self.get_device_id(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            training_status,
            node_id,
        };

        let response = self.client
            .post(&format!("{}/api/training-data", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let api_response: ApiResponse = response.json().await?;
        Ok(api_response)
    }

    /// 获取设备ID（生成或读取持久化的设备ID）
    pub fn get_device_id(&self) -> String {
        // 这里可以从配置文件或注册表读取，或者生成一个新的
        // 为了简单起见，我们使用一个基于机器信息的ID
        use std::process::Command;
        
        if let Ok(output) = Command::new("wmic")
            .args(&["csproduct", "get", "UUID", "/format:list"])
            .output() 
        {
            if let Ok(output_str) = String::from_utf8(output.stdout) {
                for line in output_str.lines() {
                    if line.starts_with("UUID=") {
                        if let Some(uuid) = line.split('=').nth(1) {
                            return uuid.trim().to_string();
                        }
                    }
                }
            }
        }
        
        // 备选方案：使用MAC地址
        if let Ok(output) = Command::new("getmac")
            .args(&["/format", "list"])
            .output()
        {
            if let Ok(output_str) = String::from_utf8(output.stdout) {
                for line in output_str.lines() {
                    if line.contains("Physical Address") {
                        if let Some(mac) = line.split('=').nth(1) {
                            return mac.trim().replace("-", ":");
                        }
                    }
                }
            }
        }
        
        // 最后备选：生成随机UUID
        uuid::Uuid::new_v4().to_string()
    }

    /// 获取设备元数据
    fn get_device_metadata(&self) -> DeviceMetadata {
        let mut capabilities = HashMap::new();
        
        // 添加系统信息
        capabilities.insert("os".to_string(), serde_json::Value::String(std::env::consts::OS.to_string()));
        capabilities.insert("arch".to_string(), serde_json::Value::String(std::env::consts::ARCH.to_string()));
        capabilities.insert("family".to_string(), serde_json::Value::String(std::env::consts::FAMILY.to_string()));
        
        DeviceMetadata {
            platform: "windows".to_string(), // 可以动态检测
            app_version: "0.1.0".to_string(), // 从Cargo.toml读取
            node_id: None, // 可以从Node获取
            capabilities,
        }
    }

    /// 节点无法联系部分节点时，请求重新分配新的节点
    pub async fn reassign_node(&self, failed_nodes: Vec<String>, current_splits: Vec<ModelSplit>, request_id: String) -> Result<NodeReassignmentResponse> {
        let payload = NodeReassignmentPayload {
            device_id: self.get_device_id(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            failed_nodes,
            current_splits,
            request_id,
        };

        let response = self.client
            .post(&format!("{}/api/reassign-node", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let reassignment_response: NodeReassignmentResponse = response.json().await?;
        Ok(reassignment_response)
    }

    /// 节点上报自身状态和硬件信息到 /api/node-info 端点
    pub async fn upload_node_info(&self, node_info: NodeInfo) -> Result<ApiResponse> {
        let payload = serde_json::json!({
            "device_id": self.get_device_id(),
            "timestamp": chrono::Utc::now().to_rfc3339(),
            "node_info": node_info,
        });

        let response = self.client
            .post(&format!("{}/api/node-info", self.base_url))
            .json(&payload)
            .send()
            .await?;

        let api_response: ApiResponse = response.json().await?;
        Ok(api_response)
    }

    /// 根据已上报信息检查节点健康状态
    pub async fn check_node_health(&self, node_id: String) -> Result<NodeHealthResponse> {
        let response = self.client
            .get(&format!("{}/api/node-health?node_id={}", self.base_url, node_id))
            .send()
            .await?;

        let health_response: NodeHealthResponse = response.json().await?;
        Ok(health_response)
    }

    /// 测试连接
    pub async fn test_connection(&self) -> Result<bool> {
        match self.client
            .get(&format!("{}/api/health", self.base_url))
            .send()
            .await
        {
            Ok(response) => Ok(response.status().is_success()),
            Err(_) => Ok(false),
        }
    }
}
